{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b437a3",
   "metadata": {},
   "source": [
    "## Agentic Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c67cde",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Workflows\n",
    "\n",
    "> ðŸ§  \"LLM is embedded in predefined code paths\"\n",
    "\n",
    "![Workflows](./images/workflows_basic.png)\n",
    "\n",
    "### ðŸª„ Prompt Chaining\n",
    "- LLMs are called sequentially.\n",
    "- Each step uses the output from the previous as input.\n",
    "- **Example:**\n",
    "    - Step 1: Summarize a document.\n",
    "    - Step 2: Extract entities from the summary.\n",
    "\n",
    "### âš¡ Parallelization\n",
    "- Input is processed simultaneously by multiple LLM instances.\n",
    "- Each LLM task is independent.\n",
    "\n",
    "- **Example:**\n",
    "    - Given an article, generate summary, sentiment, and questions in parallel.\n",
    "\n",
    "**ðŸ”‘ Key Insight:**\n",
    "- LLMs are used like functions \n",
    "- the logic is entirely controlled by predefined code, not the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c9633f",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ LLM-Controlled Workflows\n",
    "> ðŸ§  \"LLM directs control flow through predefined code paths\"\n",
    "\n",
    "![Workflow Controlled](./images/workflows_controlled.png)\n",
    "\n",
    "### ðŸ‘¨â€ðŸ­ Orchestrator-Worker\n",
    "- One LLM (the orchestrator) splits tasks and delegates to worker LLMs.\n",
    "- A synthesizer might merge their outputs.\n",
    "\n",
    "- **Example:**\n",
    "\n",
    "    - Orchestrator: \"Summarize, analyze tone, and generate insights.\"\n",
    "\n",
    "    - Workers do each part. The synthesizer merges results.\n",
    "\n",
    "### ðŸ§ª Evaluator-Optimizer\n",
    "- Generator creates outputs, Evaluator scores them, and feedback loops improve the result.\n",
    "\n",
    "- Can be seen as self-critique or reflection.\n",
    "\n",
    "- **Example:**\n",
    "    - Generate multiple answers â†’ score them â†’ choose best or retry generation.\n",
    "\n",
    "### ðŸš¦ Routing\n",
    "- A Router LLM decides which of several paths/tools should process the input.\n",
    "\n",
    "- Example:\n",
    "    - User query â†’ Router chooses sentiment analysis vs summarization vs translation model.\n",
    "\n",
    "**ðŸ”‘ Key Insight:** LLMs start to play a meta-role â€“ they decide how to use other LLMs or tools, though still within a fixed structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6cf338",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Agent\n",
    "> ðŸ§  \"LLM directs its own actions based on environmental feedback\"\n",
    "\n",
    "![Agent Workflow](./images/agent_autonomous.png)\n",
    "\n",
    "### Autonomous Agent Loop:\n",
    "- LLM observes the environment (In), decides an action, uses a Tool, and receives feedback.\n",
    "- Loop continues until a goal is reached.\n",
    "- Tools can be:\n",
    "    - Web search\n",
    "    - File readers\n",
    "    - Code executors\n",
    "    - External APIs\n",
    "\n",
    "- Example:\n",
    "\n",
    "    - ReAct (Reasoning + Acting) pattern: LLM reasons, takes an action, gets observation, and loops.\n",
    "\n",
    "    - LangChain Agent or AutoGPT: LLM decides and acts dynamically using tools and feedback.\n",
    "\n",
    "**ðŸ”‘ Key Insight:** LLM is **not just usedâ€”it drives the process**, learns from feedback, and iterates autonomously."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
