{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4ee49a",
   "metadata": {},
   "source": [
    "## React Agent\n",
    "\n",
    "React => **Reasoning** + **Acting**\n",
    "\n",
    "**Objettive:**\n",
    "- Learn how to create tools.\n",
    "- Creating `ReAct graph`\n",
    "- Work With different message type like `ToolMessage`\n",
    "- Use ``Annotated`` typing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c51fc05",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6473ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# typing\n",
    "from typing import Annotated, TypedDict, List, Sequence\n",
    "\n",
    "# langchain\n",
    "from langchain_core.messages import BaseMessage, ToolMessage, SystemMessage, HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# langgraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835d099",
   "metadata": {},
   "source": [
    "**Why use Annotation?**\n",
    "- typing.Annotated\n",
    "- Describes / annotates a variable. \n",
    "- Sort of like, context of a value.\n",
    "- For more reference: [Typing Docs](https://docs.python.org/3/library/typing.html#typing.Annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "146f58f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This has to be email.',)\n"
     ]
    }
   ],
   "source": [
    "email = Annotated[str, 'This has to be email.']\n",
    "\n",
    "print(email.__metadata__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068a34f",
   "metadata": {},
   "source": [
    "**add_message usage**\n",
    "- Reducer function\n",
    "- Merges the state returned from node.\n",
    "- No need to return all values, just a desirable key and value as a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4dde57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without reducer:\n",
    "state = {\"messages\": [\"Hi\"]}\n",
    "update = {\"messages\": [\"Hello how are you ?\"]}\n",
    "new_state = {\"messages\": [\"Hello how are you ?\"]} # no state is appended\n",
    "\n",
    "# with reducer\n",
    "state = {\"messages\": [\"Hi\"]}\n",
    "update = {\"messages\": [\"Hello how are you ?\"]}\n",
    "new_state = {\"messages\": [\"Hi\",\"Hello how are you ?\"]} # state is appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "89f864aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED      \n",
      "llama3:instruct            365c0bd3c000    4.7 GB    7 weeks ago      \n",
      "llama3.1:latest            46e0c10c039e    4.9 GB    7 weeks ago      \n",
      "llama3.2:1b                baf6a787fdff    1.3 GB    2 months ago     \n",
      "gemma2:latest              ff02c3702f32    5.4 GB    2 months ago     \n",
      "llama3:8b                  365c0bd3c000    4.7 GB    3 months ago     \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    4 months ago     \n",
      "qwen2.5-coder:1.5b-base    02e0f2817a89    986 MB    4 months ago     \n",
      "llama3.1:8b                46e0c10c039e    4.9 GB    4 months ago     \n",
      "sqlcoder:7b                77ac14348387    4.1 GB    5 months ago     \n",
      "deepseek-r1:latest         0a8c26691023    4.7 GB    5 months ago     \n",
      "mistral:latest             f974a74358d6    4.1 GB    5 months ago     \n",
      "llava:latest               8dd30f6b0cb1    4.7 GB    11 months ago    \n",
      "llama3:latest              365c0bd3c000    4.7 GB    11 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4aed07",
   "metadata": {},
   "source": [
    "**Agent State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d37eea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence: https://docs.python.org/3/glossary.html#term-sequence\n",
    "# Base Message: https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html#basemessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f857fb9",
   "metadata": {},
   "source": [
    "**Tools:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "80ab5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b:int):\n",
    "    \"\"\"This is an addition function that adds 2 numbers together\"\"\"\n",
    "\n",
    "    return a + b \n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b: int):\n",
    "    \"\"\"Subtraction function\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiplication function\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, subtract, multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928405ce",
   "metadata": {},
   "source": [
    "**model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "79ad9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3.1:latest\"\n",
    "\n",
    "# model = ChatOllama(model='mistral:latest').bind_tools(tools=tools)\n",
    "\n",
    "model = ChatOpenAI(model=model_name, base_url='http://localhost:11434/v1', api_key='ollama').bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658de63a",
   "metadata": {},
   "source": [
    "**Nodes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "94b21567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_call(state: AgentState):\n",
    "    sys_msg = \"\"\"\n",
    "        You are a helpful assistant, answer my question based on tools if needed. You have access to tools sum, multiply and subtract.\n",
    "        Use tools for solving sum, multiply and subtract.\n",
    "    \"\"\"\n",
    "    system_message = SystemMessage(\n",
    "        content=sys_msg\n",
    "    )\n",
    "    response = model.invoke([system_message] + state[\"messages\"])\n",
    "\n",
    "    # note that, since we re using reducer, we dont need to return all\n",
    "    return {\"messages\" : [response]}\n",
    "\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    print(last_message)\n",
    "\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "    \n",
    "\n",
    "tool_node = ToolNode(tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37836528",
   "metadata": {},
   "source": [
    "**Graph nodes and edges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "036ccc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7067bdd42ed0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# nodes\n",
    "graph.add_node('agent', model_call)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "# edges\n",
    "graph.add_edge(START, 'agent')\n",
    "graph.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "graph.add_edge('tools', 'agent') # edge from tool to agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f8e10",
   "metadata": {},
   "source": [
    "**Compile Graph and Invoke**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e3836042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 12 and 5. From a result subtract 6. Now give me a final result\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_afok1lb5', 'function': {'arguments': '{\"a\":12,\"b\":5}', 'name': 'add'}, 'type': 'function', 'index': 0}, {'id': 'call_w34al47f', 'function': {'arguments': '{\"a\":17,\"b\":6}', 'name': 'subtract'}, 'type': 'function', 'index': 0}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 330, 'total_tokens': 373, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.1:latest', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-598', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run--6e82d2a9-34d4-49b0-b7e1-c8809253d7e1-0' tool_calls=[{'name': 'add', 'args': {'a': 12, 'b': 5}, 'id': 'call_afok1lb5', 'type': 'tool_call'}, {'name': 'subtract', 'args': {'a': 17, 'b': 6}, 'id': 'call_w34al47f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 330, 'output_tokens': 43, 'total_tokens': 373, 'input_token_details': {}, 'output_token_details': {}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_afok1lb5)\n",
      " Call ID: call_afok1lb5\n",
      "  Args:\n",
      "    a: 12\n",
      "    b: 5\n",
      "  subtract (call_w34al47f)\n",
      " Call ID: call_w34al47f\n",
      "  Args:\n",
      "    a: 17\n",
      "    b: 6\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: subtract\n",
      "\n",
      "11\n",
      "content='The result of adding 12 and 5 is 17. Now, subtracting 6 from that result gives us the final answer: 11.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 166, 'total_tokens': 198, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.1:latest', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-736', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--0b1dd8ad-675c-494a-8cfd-33d77a3fb950-0' usage_metadata={'input_tokens': 166, 'output_tokens': 32, 'total_tokens': 198, 'input_token_details': {}, 'output_token_details': {}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 12 and 5 is 17. Now, subtracting 6 from that result gives us the final answer: 11.\n"
     ]
    }
   ],
   "source": [
    "agent = graph.compile()\n",
    "\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", \"Add 12 and 5. From a result subtract 6. Now give me a final result\")]}\n",
    "print_stream(agent.stream(inputs, stream_mode=\"values\"))\n",
    "\n",
    "# stream = agent.invoke(inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
